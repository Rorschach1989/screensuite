import argparse
import datetime
import json
import os
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

import datasets
import pandas as pd
from dotenv import load_dotenv
from smolagents import (
    AgentError,
    HfApiModel,
)
from smolagents.agents import ActionStep
from tqdm import tqdm

from geekagents.e2b_qwen import E2BVisionAgent


load_dotenv()
os.makedirs("output", exist_ok=True)

APPEND_ANSWER_LOCK = threading.Lock()


def parse_arguments():
    parser = argparse.ArgumentParser(description="Runs an agent powered by the given model on smolagent benchmark.")
    parser.add_argument(
        "--date",
        type=str,
        default=None,
        help="The date for the evaluation.",
    )
    parser.add_argument(
        "--eval-dataset",
        type=str,
        default="smolagents/benchmark-v1",
    )
    # The eval dataset is gated, so you must first visit its page to request access: https://huggingface.co/datasets/smolagents-benchmark/benchmark-v1
    parser.add_argument(
        "--model-id",
        type=str,
        default="Qwen/Qwen2.5-VL-72B-Instruct",
        help="The model ID to use for the specified model type",
    )
    parser.add_argument(
        "--parallel-workers",
        type=int,
        default=8,
        help="The number of processes to run in parallel",
    )
    return parser.parse_args()


def serialize_agent_error(obj):
    if isinstance(obj, AgentError):
        return {"error_type": obj.__class__.__name__, "message": obj.message}
    else:
        return str(obj)


def append_answer(entry: dict, jsonl_file: str) -> None:
    jsonl_file = Path(jsonl_file)
    jsonl_file.parent.mkdir(parents=True, exist_ok=True)
    with APPEND_ANSWER_LOCK, open(jsonl_file, "a", encoding="utf-8") as fp:
        fp.write(json.dumps(entry) + "\n")
    assert os.path.exists(jsonl_file), "File not found!"

from .reformulator import prepare_response

def answer_single_question(example, model, answers_file):

    # Initialize agent
    agent = E2BVisionAgent(
        model=model,
        e2b_api_key=args.api_key,
        output_dir=args.output_dir,
        resolution=(1024,768),
        max_steps=20
    )

    augmented_question = example["question"]

    start_time = time.time()

    try:
        # Run agent ðŸš€
        agent.run(augmented_question)
        token_count = agent.monitor.get_total_token_counts()

        agent_messages = agent.write_memory_to_messages(summary_mode=True)

        reformulated_answer = prepare_response(augmented_question, agent_messages, reformulation_model=model)

        # Remove memory from logs to make them more compact.
        for step in agent.memory.steps:
            if isinstance(step, ActionStep):
                step.agent_memory = None
        intermediate_steps = str(agent.memory.steps)
        end_time = time.time()
    except Exception as e:
        print("Error on ", augmented_question, e)
        intermediate_steps = []
    end_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    annotated_example = {
        "model_id": model.model_id,
        "question": augmented_question,
        "original_question": example["question"],
        "answer": reformulated_answer,
        "true_answer": example["true_answer"],
        "source": example["source"],
        "intermediate_steps": intermediate_steps,
        "start_time": start_time,
        "end_time": end_time,
        "token_counts": token_count,
    }
    append_answer(annotated_example, answers_file)


def answer_questions(
    eval_ds,
    model,
    date,
    action_type: str = "code",
    output_dir: str = "output",
    push_answers_to_hub: bool = False,
    parallel_workers: int = 32,
):
    date = date or datetime.date.today().isoformat()
    model_id = model.model_id

    for task in eval_ds:
        file_name = f"{output_dir}/{model_id.replace('/', '__')}__{action_type}__{task}__{date}.jsonl"
        print(f"Starting processing and writing output to '{file_name}'")
        answered_questions = []
        if os.path.exists(file_name):
            with open(file_name, "r") as f:
                for line in f:
                    answered_questions.append(json.loads(line)["original_question"])

        examples_todo = [example for example in eval_ds[task] if example["question"] not in answered_questions]
        print(f"Launching {parallel_workers} parallel workers.")

        with ThreadPoolExecutor(max_workers=parallel_workers) as exe:
            futures = [
                exe.submit(answer_single_question, example, model, file_name, action_type) for example in examples_todo
            ]
            for f in tqdm(as_completed(futures), total=len(examples_todo), desc="Processing tasks"):
                f.result()

        print("All tasks processed.")


if __name__ == "__main__":
    args = parse_arguments()

    if args.parallel_workers > 20:
        raise ValueError("E2B free tier is limited to 20 parallel workers.")

    eval_ds = datasets.load_dataset(args.eval_dataset)

    from smolagents import HfApiModel

    model = HfApiModel(args.model_id, provider="hyperbolic", max_tokens=8192)

    answer_questions(
        eval_ds,
        model,
        args.date,
        action_type=args.agent_action_type,
        answers_dataset=args.answers_dataset,
        push_answers_to_hub=args.push_answers_to_hub,
        parallel_workers=args.parallel_workers,
    )
