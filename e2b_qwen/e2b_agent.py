import argparse
import ast
import os
import re
import time
from io import BytesIO
from textwrap import dedent
from typing import Any, Dict, List, Optional, Tuple, Union

# Qwen2.5VL imports
import torch

# E2B imports
from e2b_desktop import Sandbox
from PIL import Image
from qwen_vl_utils import process_vision_info

# SmolaAgents imports
from smolagents import CodeAgent, tool
from smolagents.memory import ActionStep
from smolagents.models import ChatMessage, MessageRole, Model
from smolagents.monitoring import LogLevel
from transformers import AutoProcessor, Qwen2_5_VLForConditionalGeneration


class QwenVLModel(Model):
    """Model wrapper for Qwen2.5VL"""

    def __init__(self, model_path: str = "Qwen/Qwen2.5-VL-3B-Instruct", device: str = "auto"):
        super().__init__()
        self.model_path = model_path
        self.device = device
        self.model_id = model_path
        self.model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            model_path, torch_dtype="auto", device_map=device
        )
        self.processor = AutoProcessor.from_pretrained(model_path)

    def __call__(
        self, 
        messages: List[Dict[str, Any]], 
        stop_sequences: Optional[List[str]] = None, 
        **kwargs
    ) -> ChatMessage:
        """Convert a list of messages to a model input and run inference"""

        # Count images in messages - debug
        image_count = 0
        for msg in messages:
            if isinstance(msg.get("content"), list):
                for item in msg["content"]:
                    if isinstance(item, dict) and item.get("type") == "image":
                        image_count += 1

        print(f"QwenVLModel received {len(messages)} messages with {image_count} images")

        # Format the messages for Qwen2.5VL
        formatted_messages = []

        for msg in messages:
            role = msg["role"]
            if isinstance(msg["content"], list):
                content = []
                for item in msg["content"]:
                    if item["type"] == "text":
                        content.append({"type": "text", "text": item["text"]})
                    elif item["type"] == "image":
                        # Handle image path or direct image object
                        if isinstance(item["image"], str):
                            print("Image in memory")
                            content.append({"type": "image", "image": item["image"]})
                        else:
                            print("Image in temp file")
                            # Save temporary image file
                            temp_img_path = "temp_image.png"
                            item["image"].save(temp_img_path)
                            content.append({"type": "image", "image": temp_img_path})
            else:
                content = [{"type": "text", "text": msg["content"]}]

            formatted_messages.append({"role": role, "content": content})

        # Prepare for inference
        text = self.processor.apply_chat_template(
            formatted_messages, tokenize=False, add_generation_prompt=True
        )
        image_inputs, video_inputs = process_vision_info(formatted_messages)
        inputs = self.processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        )
        inputs = inputs.to(self.model.device)

        # Generate the response
        generated_ids = self.model.generate(**inputs, max_new_tokens=512)
        generated_ids_trimmed = [
            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        output_text = self.processor.batch_decode(
            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
        )[0]

        # Clean up any temporary files
        if os.path.exists("temp_image.png"):
            os.remove("temp_image.png")

        return ChatMessage(role=MessageRole.ASSISTANT, content=output_text)

    def to_dict(self) -> Dict[str, Any]:
        """Convert the model to a dictionary"""
        return {
            "class": self.__class__.__name__,
            "model_path": self.model_path,
            "device": self.device
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "QwenVLModel":
        """Create a model from a dictionary"""
        return cls(
            model_path=data.get("model_path", "Qwen/Qwen2.5-VL-3B-Instruct"),
            device=data.get("device", "auto")
        )

class E2BVisionAgent(CodeAgent):
    """Agent for e2b desktop automation with Qwen2.5VL vision capabilities"""
    def __init__(
        self,
        model: QwenVLModel,
        e2b_api_key: str,
        tools: List[tool] = None,
        max_steps: int = 15,
        verbosity_level: LogLevel = LogLevel.DEBUG,
        resolution: Tuple[int, int] = (1024, 768),
        **kwargs
    ):
        # E2B setup
        self.e2b_api_key = e2b_api_key
        self.resolution = resolution

        print(f"Verbosity level set to {verbosity_level}")

        self.planning_interval = 5

        # Initialize base agent
        super().__init__(
            tools=tools or [],
            model=model,
            max_steps=max_steps,
            verbosity_level=verbosity_level,
            planning_interval = self.planning_interval,
            **kwargs
        )


        self.desktop = None
        self.setup_e2b_sandbox()

        # Add default tools
        self._setup_desktop_tools()
        self.step_callbacks.append(self.take_screenshot_callback)

    def setup_e2b_sandbox(self):
        """Initialize the e2b desktop sandbox"""
        print("Starting e2b desktop sandbox...")
        self.desktop = Sandbox(
            api_key=self.e2b_api_key,
            resolution=self.resolution,
            # timeout=3600  # 1 hour timeout
        )
        self.desktop.stream.start()
        self.stream_url = self.desktop.stream.get_url()
        print(f"E2B desktop sandbox started with stream URL: {self.stream_url}")

        # Store screen dimensions
        self.width, self.height = self.desktop.get_screen_size()
        print(f"Screen size: {self.width}x{self.height}")

        # Add screen info to state
        self.state["screen_width"] = self.width
        self.state["screen_height"] = self.height

    def _setup_desktop_tools(self):
        """Register all desktop tools"""
        @tool
        def click(x: int, y: int) -> str:
            """
            Performs a left-click at the specified coordinates
            Args:
                x: The x coordinate (horizontal position)
                y: The y coordinate (vertical position)
            """
            self.desktop.move_mouse(x, y)
            self.desktop.left_click()
            return f"Clicked at coordinates ({x}, {y})"

        @tool
        def right_click(x: int, y: int) -> str:
            """
            Performs a right-click at the specified coordinates
            Args:
                x: The x coordinate (horizontal position)
                y: The y coordinate (vertical position)
            """
            self.desktop.move_mouse(x, y)
            self.desktop.right_click()
            return f"Right-clicked at coordinates ({x}, {y})"

        @tool
        def double_click(x: int, y: int) -> str:
            """
            Performs a double-click at the specified coordinates
            Args:
                x: The x coordinate (horizontal position)
                y: The y coordinate (vertical position)
            """
            self.desktop.move_mouse(x, y)
            self.desktop.double_click()
            return f"Double-clicked at coordinates ({x}, {y})"

        @tool
        def move_mouse(x: int, y: int) -> str:
            """
            Moves the mouse cursor to the specified coordinates
            Args:
                x: The x coordinate (horizontal position)
                y: The y coordinate (vertical position)
            """
            self.desktop.move_mouse(x, y)
            return f"Moved mouse to coordinates ({x}, {y})"

        @tool
        def type_text(text: str, delay_in_ms: int = 75) -> str:
            """
            Types the specified text at the current cursor position
            Args:
                text: The text to type
                delay_in_ms: Delay between keystrokes in milliseconds
            """
            self.desktop.write(text, delay_in_ms=delay_in_ms)
            return f"Typed text: '{text}'"

        @tool
        def press_key(key: str) -> str:
            """
            Presses a keyboard key
            Args:
                key: The key to press (e.g., "Return", "tab", "ctrl+c")
            """
            if key == "enter":
                key = "Return"
            self.desktop.press(key)
            return f"Pressed key: {key}"

        @tool
        def scroll(direction: str = "down", amount: int = 1) -> str:
            """
            Scrolls the page
            Args:
                direction: The direction to scroll ("up" or "down")
                amount: The amount to scroll
            """
            self.desktop.scroll(direction=direction, amount=amount)
            return f"Scrolled {direction} by {amount}"

        @tool
        def wait(seconds: float) -> str:
            """
            Waits for the specified number of seconds
            Args:
                seconds: Number of seconds to wait
            """
            time.sleep(seconds)
            return f"Waited for {seconds} seconds"

        @tool
        def open_url(url: str) -> str:
            """
            Opens the specified URL in the default browser
            Args:
                url: The URL to open
            """
            # Make sure URL has http/https prefix
            if not url.startswith(("http://", "https://")):
                url = "https://" + url

            self.desktop.open(url)
            # Give it time to load
            time.sleep(2)
            return f"Opened URL: {url}, what should be the next tool to execute? only provide the next tool call to execute"


        # Register the tools
        self.tools["click"] = click
        self.tools["right_click"] = right_click
        self.tools["double_click"] = double_click
        self.tools["move_mouse"] = move_mouse
        self.tools["type_text"] = type_text
        self.tools["press_key"] = press_key
        self.tools["scroll"] = scroll
        self.tools["wait"] = wait
        self.tools["open_url"] = open_url


    def take_screenshot_callback(self, memory_step: ActionStep, agent=None) -> None:
        """Callback that takes a screenshot after a step completes"""
        print(f"Taking screenshot after step {memory_step.step_number}")
        try:
            current_step = memory_step.step_number
            time.sleep(1.0) # Let things happen on the desktop
            screenshot_bytes = self.desktop.screenshot()
            image = Image.open(BytesIO(screenshot_bytes))

            # Create a unique filename
            screenshot_path = f"screenshot_{int(time.time() * 1000)}.png"
            image.save(screenshot_path)
            print(f"Saved screenshot to {screenshot_path}")

            for previous_memory_step in agent.memory.steps:  # Remove previous screenshots from logs for lean processing
                if isinstance(previous_memory_step, ActionStep) and previous_memory_step.step_number <= current_step - 2:
                    previous_memory_step.observations_images = None

            # Add to the current memory step
            memory_step.observations_images = [image.copy()] # This takes the original image directly.

            # # If there was an observation, preserve it
            # if hasattr(memory_step, "observations") and memory_step.observations:
            #     memory_step.observations = f"{memory_step.observations}\nScreenshot saved to: {screenshot_path}"
            # else:
            #     memory_step.observations = f"Screenshot saved to: {screenshot_path}"

        except Exception as e:
            print(f"Error taking screenshot: {e}")

    def close(self):
        """Clean up resources"""
        if self.desktop:
            print("Stopping e2b stream...")
            self.desktop.stream.stop()

            print("Killing e2b sandbox...")
            self.desktop.kill()
            print("E2B sandbox terminated")


def main():
    os.environ["E2B_API_KEY"] = "e2b_1da1c9786e4bd971e6e105cf95a423f588403b73"

    """Run the E2B Vision Agent"""
    parser = argparse.ArgumentParser(description="Run the E2B Vision Agent")
    parser.add_argument("task", help="The task to perform on the desktop")
    parser.add_argument("--api-key", default=os.environ.get("E2B_API_KEY"), help="E2B API key")
    parser.add_argument("--resolution", default="1024,768", help="Screen resolution (width,height)")
    parser.add_argument("--model-path", default="Qwen/Qwen2.5-VL-3B-Instruct", help="Path to Qwen2.5VL model")
    args = parser.parse_args()

    if not args.api_key:
        raise ValueError("E2B API key not provided. Set E2B_API_KEY environment variable or use --api-key")

    width, height = map(int, args.resolution.split(","))

    # Initialize model
    # model = QwenVLModel(model_path=args.model_path)

    from smolagents import HfApiModel

    model = HfApiModel("Qwen/Qwen2.5-VL-72B-Instruct", provider="hyperbolic")

    # Initialize agent
    agent = E2BVisionAgent(
        model=model,
        e2b_api_key=args.api_key,
        resolution=(width, height),
        max_steps=20
    )

    try:
        # Run the agent
        result = agent.run(args.task+f"""The desktop has a resolution of {agent.resolution[0]}x{agent.resolution[1]}.
            You cannot use find_element_by_xpath.

            Always analyze the latest screenshot carefully before performing actions. Make sure to:
            1. Look at elements on the screen to determine what to click or interact with
            2. Use precise coordinates for mouse movements and clicks
            3. Wait for page loads or animations to complete using the wait() tool

            When you receive a task, break it down into step-by-step actions. Look at the current screenshot to know which planned action to execute.
            We can only execute one action at a time.
            """)
        print(f"\nTask completed with result: {result}")
    finally:
        # Clean up
        agent.close()

if __name__ == "__main__":
    main()
